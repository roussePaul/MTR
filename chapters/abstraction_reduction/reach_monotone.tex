\newcommand{\xinf}{\underline{\vect{x}}}%
\newcommand{\xsup}{\overline{\vect{x}}}%
\newcommand{\xinit}{\vect{x}_0}%
\newcommand{\xn}{\vect{x}_n}%
\newcommand{\un}{\vect{u}_n}%
\newcommand{\wn}{\vect{w}_n}%
\newcommand{\yn}{\vect{y}_n}%
\newcommand{\xnn}{\vect{x}_{n+1}}%
\newcommand{\Sproc}{$\mathcal{S}$-procedure}%
%
\section{Linear systems}
Let the linear system $S$ defined by:
\begin{equation} \label{lin_sys}
S:
\left\{
\begin{aligned}
\xnn &= A \xn + B \un + E \wn \\
\yn &= C \xn
\end{aligned}
\right.
\end{equation}

\cite{liu2014abstraction} have been investigating boundedness property in order ignore one part of the abstraction.
Really good introduction about hierarchical control approach, give references.

\comment{Try to justify the fact that the system definition for the linear system is different from the theory used before.}

We will translate the boundedness assumption of $\Xunobs(\Pastuseq)$ by making further assumptions on the system $\Sunobs$:
\begin{itemize}[noitemsep,nolistsep]
\item the image of the input set on $\SSunobs$ is bounded,
\item the image of the noise set on $\SSunobs$ is bounded,
\item the system is asymptotically stable on the subspace $\SSunobs$.
\end{itemize}
These assumptions are not a necessary conditions in order to create the abstraction $\sysa$.

Finally, we adopt the following definition of the system $S$:
\begin{equation} \label{lin_sys_decoupled}
S:
\left\{
\begin{aligned}
\xnn &= 
\begin{bmatrix} A_z & A_{zr}\\ 0 & A_r \end{bmatrix} \xn
+\begin{bmatrix} B_z \\ B_r \end{bmatrix} \un
+\begin{bmatrix} E_z\\ E_r \end{bmatrix} \wn\\
\yn &= \xobs_n \\
\un &\in \U \\
\wn &\in \W \\
\end{aligned}
\right.
\end{equation}
with,
\begin{align*}
\xn = \begin{bmatrix}
\xobs_n\\
\xunobs_n
\end{bmatrix}
\textrm{, }
\un = \begin{bmatrix}
\uobs_n\\
\uunobs_n
\end{bmatrix}
\textrm{, }
\wn = \begin{bmatrix}
\wobs_n\\
\wunobs_n
\end{bmatrix}
\end{align*}
where the system $\Sunobs=(A_r,B_r,E_r)$ is asymptotically stable, input set $\Uunobs$ and noise sets $\Wunobs$ (respective projection of $\U$ and $\W$ on $\SSunobs$) are bounded.

This system definition might seems restrictive as we assume that the unobserved part of the system is independent of the observed part.
However, this structure is met in many mechanical systems (mainly because of the Newton's second law of mechanic).
This make this model relevant especially in the case of robot motion planning.

\section{Reachable set}
The computation of the reached sets is a field in control theory on its own.
So the reader might refer to the large literature about it for more precise algorithms in order to find invariants and the reachable sets.

In this part, we will present 2 methods to compute the reachable sets.
The first one will only be valid for monotone systems. Even if this subclass of dynamical systems is restrictive, it is possible to obtain closed form solutions for reachable sets which is useful for further studies of the input extended state abstraction model.
The second one is based on ellipsoidal bounding methods which can be applied to a wider class of systems.


As the computation of the reachable sets is not dependant on the entire system according to the definition of the system \ref{lin_sys_decoupled}, we will adopt a simpler notation for this section.
We will use the notation of \ref{lin_sys}, with the assumptions of the unobserved system (boundedness of input and noise sets and asymptotically stable).
All these results will be then used for the unobserved system $\Sunobs$.

\subsection{Monotone systems}
In order to get a literal expression of the reachable sets, we have investigated a subset of the linear systems: the \textit{linear monotone systems}.

Monotone systems are systems that keep a partial ordering relation $\mleq$ between 2 trajectories while time passes.
The partial ordering of the state space allow us to over approximate any bounded set $X$ with 2 vectors $\xinf$ and $\xsup$ so that $\forall \x \in X, \xinf \mleq \x \and \x \mleq \xsup$. We can define a segment of $\R^n$ by $[\xinf,\xsup] = \{\x \in \R^n \mid  \xinf \mleq \x \and \x \mleq \xsup\}$.
More over, for any trajectory starting from $\xinit \in [\xinf,\xsup]$, we know that for a monotonic system:
\begin{equation}
\forall k \in \mathbb{N}, \traj(\xinit,k) \in [\traj(\xinf,k),\traj(\xsup,k)]
\end{equation}

In order to obtain a literal form of the input extended state abstraction, we assume the subsystem $S$ is a monotone asymptotically stable system and that the inputs and noise are bounded by a monotonic interval (if it is not the case, it is still possible to over approximate the bounds with a monotonic interval):
\begin{equation*}
\U \subseteq \left [ \minf{\vu}, \msup{\vu} \right ]
\textrm{, }
\W \subseteq \left [ \minf{\w}, \msup{\w} \right ]
\end{equation*}

As we mentioned in section \ref{sec:abstraction}, the computation of the set $\X(\Pastuseq)$ are done in 2 steps: computation of the invariant and computation of the image of this invariant after applying $\Pastuseq$.
We will take advantage of the monotonic structure by expressing all the sets as monotone interval of the state space.

As the system $S$ is asymptotically stable, the matrix $I-A$ as eigenvalues strictly greater than $0$ and is invertible.
We can define:
\begin{equation}
\begin{split}
\msup{\x} &= (I-A)^{-1} (B \msup{\vu} + E \msup{\w})\\
\minf{\x} &= (I-A)^{-1} (B \minf{\vu} + E \minf{\w})\\
\end{split}
\end{equation}
which correspond to the bounds of the smallest monotonic invariant set $\Xinv$ of the system.
So:
\begin{equation}
\Xinv = \left[ \minf{\x}, \msup{\x} \right]
\end{equation}

Let $\traj(\x,U,W)$ the trajectory function of the system $S$ starting from $\x_0$
applying the control sequence $U \in {\U}^k$
with the noise sequence $W \in {\W}^k$ and $k \in \mathbb{N}$.
As the system $S$ is monotone,
\begin{equation}
\forall \x_0 \in \left [\minf{\x}, \msup{\x} \right ],
\forall U \in {\U}^k,
\forall W \in {\W}^k,
\traj (\x_0,U,W)
\in \left[ \minf{\x}, \msup{\x} \right]
\end{equation}

If the initial state of the unobserved system is in $\left[ \minf{\x}, \msup{\x} \right]$, then every trajectories will stay in this set.

For $U \in \U^k$, let $\X(U)$ the subset of $\mathbb{R}^n$ defined by:
\begin{equation}
\X(U) = \left[ 
\traj (\minf{\x},U,\minf{\w}),
\traj (\msup{\x},U,\msup{\w})
\right]
\end{equation}
$\X(U)$ correspond to the set of all the possible successors after applying the control sequence $U$ on the system $S$. This results come from the monotonic property.
This can be summarized in the following property:
\begin{equation}
\forall U \in \U^k,
\forall \x \in \left[\minf{\x}, \msup{\x} \right],
\forall W \in \W^k,
\traj (\x,U,W) \in \X(U)
\end{equation}

%TODO -> TIKZ ADD SCHEMATICS ON MONOTONIC SYSTEMS

\subsection{Extension to non monotonic systems}
The monotonicity property is really convenient in order to do the computations.
However, this is a strong assumption on the system: any system that have a non pure real eigenvalues is not monotonic.

In this part we will present an ellipsoidal bounding approach.
The main idea is to use ellipsoidal sets to that contains all the possible states of the system starting from $\Xinv$.

\newcommand{\ellipse}{\mathcal{E}}%
This problem does not have a closed form solution, however it is possible to formalize it as a convex minimization problem under some assumptions about the input and noise set.
An ellipsoidal set $\ellipse \in \mathbb{R}^n$ can be expressed with:
\begin{equation}
\ellipse  = \{\x \in \mathbb{R}^n \mid \x^T P \x + 2 p^T \x + r \leq 1 \} 
\end{equation}
where $P$ is a positive definite matrix.

The problem of determining the reached sets of the system $S$ for a sequence of input $U \in \U^k$ can be translated by:
\begin{equation} \label{min_prob}
\begin{aligned}
\min_{\ellipse} & Vol(\ellipse)\\
\textrm{s.t.}   & \X(U) \subseteq \ellipse
\end{aligned}
\end{equation}
literally, we are searching for the ellipsoidal set $\ellipse$ that approximate the best (in term of volume of successors) the set $\X(U)$

If the bounds on the inputs and on the noise are expressible in term of LMI, then we can solve this problem as a LMI minimization problem.

We will now formalize the problem in term of LMI constraints.
The noise and inputs sets will be model as centred ellipsoids:
\begin{equation}
\begin{aligned}
\U &= \{ \vu \in \R^{n_u} \mid \vu^T R_u \vu < 1 \}\\
\W &= \{ \w \in \R^{n_w} \mid \w^T R_w \w < 1 \}\\
\end{aligned}
\end{equation}

In order to express the constraints $\X(U) \subseteq \ellipse$ of problem \ref{min_prob}, we will successively bound the state in ellipsoids $\ellipse_k$ beginning with the set $\Xinv = \ellipse_0$.

we will now define the following functions for $k \in \mathbb{N}$:
\begin{equation}
f_k(\x) = \x^T P_k \x + 2 p_k^T \x + r_k
\end{equation}
for $\x \in \R^n$, and the associated sets:
\begin{equation}
\ellipse_k = \{ \x \in \R^n \mid f_k(\x) \leq 1 \}
\end{equation}
for $k\in\mathbb{N}$.

For every trajectories $\{\x_i\}_{i\in \mathbb{N}}$, for $i \in \mathbb{N}$, $\ellipse_0$ is an invariant set:
\begin{equation}\label{inv_ellipse}
\x_i \in \ellipse_0 \Rightarrow \x_{i+1} \in \ellipse_0
\end{equation}

For every trajectories $\{\x_i\}_{i \in \mathbb{N}}$ starting from the initial state $x_0 \in \ellipse_0$ associated with the input sequence $U$, for $i \in \leftint 1,k \rightint$:
\begin{equation} \label{next_ellipse}
\x_i \in \ellipse_i \Rightarrow \x_{i+1} \in \ellipse_{i+1}
\end{equation}

As $\U$ and $\W$ are centred, and by symmetry of the system, we know that $p_0 = 0$$r_0 = 0$.

Please note the following equivalence:
\begin{align*}
\x_{i+1} \in \ellipse_0 
&\Leftrightarrow f_0(\x_{i+1}) \leq 1 \\
&\Leftrightarrow \s_i^T M_0 \s_i \leq 0 && \text{(Schur complement)}
\end{align*}
where
\begin{equation}
M_0 =
\begin{bmatrix}
A^T P_0 A & A^T P_0 B & A^T P_0 E & 0 \\
B^T P_0 A & B^T P_0 B & B^T P_0 E & 0 \\
E^T P_0 A & E^T P_0 B & E^T P_0 E & 0 \\
0       & 0       & 0       & -1 \\
\end{bmatrix}
\end{equation}
and $\s_i = \left[ \x_i^T, \vu_i^T, \w_i^T, 1 \right]^T$.

\begin{align*}
\x_{i} \in \ellipse_j 
&\Leftrightarrow f_j(\x_{i}) \leq 1 \\
&\Leftrightarrow \s_i^T M^P_{j} \s_i \leq 0 && \text{(Schur complement)}
\end{align*}
where
\begin{equation}
M^P_{j} =
\begin{bmatrix}
  P_j 	& 0 & 0 & p_j\\
  0 	& 0 & 0 & 0\\
  0 	& 0 & 0 & 0\\
  p^T 	& 0 & 0 & r_j-1\\
\end{bmatrix}
\end{equation}

And
\begin{align*}
\x_{i+1} \in \ellipse_j
&\Leftrightarrow f_j(\x_{i+1}) \leq 1 \\
&\Leftrightarrow \st_i^T M_j \st_i \leq 0 && \text{(Schur complement)}
\end{align*}
where $\st_i = \left[ \x_i^T, \w_i^T, 1 \right]^T$ and
\begin{equation}
M_j =
\begin{bmatrix}
A^T P_j A 			& A^T P_0 E 		& A^T (p_j + B \vu_i ) \\
E^T P_j A 			& E^T P_0 E 		& E^T (p_j + B \vu_i) \\
(p_j + \vu_i B) A 	& (p_j^T + \vu_i^T B^T) E  &
\vu_i^T B^T P_j B \vu_i + 2 p^T B \vu_i + r_j - 1\\
\end{bmatrix}
\end{equation}

From now we will use these equivalences in order to express the implication  \ref{inv_ellipse} and \ref{lin_sys} in term of LMI.
Implication \ref{inv_ellipse} is equivalent to:
\begin{equation}
\left\{
\begin{aligned}
f_0(\x_i)   &\leq 1\\
\vu_i^T R_u \vu_i &\leq 1\\
\w_i^T R_w \w_i &\leq 1
\end{aligned}
\right.
\Rightarrow
f_0(\x_{i+1}) \leq 1
\end{equation}
Let define:
\begin{equation}
M_u = \begin{bmatrix}
0&0&0&0\\
0&R_u&0&0\\
0&0&0&0\\
0&0&0&-1\\
\end{bmatrix}
\textrm{ and }
M_w = \begin{bmatrix}
0&0&0&0\\
0&0&0&0\\
0&0&R_w&0\\
0&0&0&-1\\
\end{bmatrix}
\end{equation}

By using the \Sproc{}, if it exists $a,b,c \in \R$ so that $a,b,c>0$ and:
\begin{equation}
M_0 \leq a M^P_0 + b M_w + c M_u
\end{equation}
then the implication \ref{inv_ellipse} is satisfied.

\newcommand{\ai}{\alpha_i}
\newcommand{\bi}{\beta_i}
In the same way, if it exists $\ai,\bi \in \R$ so that $\ai,\bi>0$ and:
\begin{equation}
M_{i+1} \leq \ai M^P_i + \bi M_w
\end{equation}
then the implication \ref{next_ellipse} is satisfied.

Without loss of generality, we will add the following constraint: $r_k = p_k^T P_k p_k$. This does not restrict ellipsoidal sets and it reduce the number of free variable of the minimization problem.

The \Sproc{} guaranty to keep convexity properties. However, it is just a sufficient condition, so we might not found a solution even if there exist one.

%TODO plot of ellipsoidal sets.
%TODO Treat the case where the set of inputs is continuous
Talk about the cost function, why does the problem are equivalent

\cite{Polyak200815349}
\cite{LMI_book}
